# ğŸ“¸ Image Captioning using Deep Learning

This project implements an **Image Captioning System** that automatically generates descriptive captions for images.  
It combines a **Convolutional Neural Network (CNN â€“ InceptionV3)** for feature extraction with a **Recurrent Neural Network (RNN â€“ LSTM)** for natural language generation.  
The model is trained and evaluated on the **Flickr8k dataset**, with performance measured using **BLEU scores**.

---

## ğŸ“ Dataset
- **Source:** [Flickr8k Dataset](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip)  
- **Total Images:** 8,000  
- **Captions:** 5 human-annotated captions per image  
- **Special Tokens:**  
  - `startseq` â†’ Start of caption  
  - `endseq` â†’ End of caption  

---

## ğŸ“Œ Model Workflow

| Step | Description |
|------|-------------|
| **1. Feature Extraction** | Images passed through **InceptionV3** â†’ 2048-dim feature vector |
| **2. Caption Preprocessing** | Cleaned, tokenized, and padded with start/end tokens |
| **3. Model Architecture** | Encoder (Dense layer) + Decoder (Embedding + LSTM) + Softmax |
| **4. Training** | Input: (Image features + partial caption) â†’ Predict next word |
| **5. Inference** | Start with `startseq`, predict words until `endseq` |

---

## ğŸ“Š Algorithms & Techniques
- **CNN (InceptionV3)** â†’ Feature extraction  
- **RNN (LSTM)** â†’ Caption generation  
- **BLEU Scores (1â€“4)** â†’ Evaluation metric  

---

## ğŸ“Œ Key Features
- Uses **InceptionV3 (pre-trained on ImageNet)** for robust visual features  
- Generates captions via **LSTM** sequence modeling  
- Evaluation with **BLEU-1 to BLEU-4**  
- Deployable via **Flask Web App** (optional ngrok for sharing)  
- Simple **image upload interface** for inference  

---

## ğŸ”§ Tech Stack
- **Programming Language:** Python  
- **Libraries:** `TensorFlow/Keras`, `NLTK`, `Flask`, `Bootstrap`, `Ngrok`  

---

## ğŸ“ˆ Model Performance Summary (BLEU Scores)

| Metric   | Score |
|----------|-------|
| **BLEU-1** | ~0.58 |
| **BLEU-2** | ~0.36 |
| **BLEU-3** | ~0.23 |
| **BLEU-4** | ~0.14 |

---

## ğŸ“Š Visualization
_Comparison of BLEU scores across n-grams_  

**Example 
<img width="940" height="581" alt="image" src="https://github.com/user-attachments/assets/40b13055-14d0-4ad0-844e-661be111cfd4" />

Output:**  
<img width="940" height="549" alt="image" src="https://github.com/user-attachments/assets/b8ced75f-0343-43ac-8ba5-47ef7f12b812" />


## ğŸš€ How to Run the Project

1. Install dependencies
   pip install -r requirements.txt

2. Run Jupyter Notebook (training & testing)
   jupyter notebook notebook.ipynb

3. OR run the Flask app
   python app.py

---

## ğŸ”® Future Improvements
- Implement Beam Search for improved fluency
- Add Attention Mechanism / Transformers
- Train on larger datasets (MS-COCO) 
- Fine-tune CNN layers for better features
- Integrate GPT-based caption refinement

---

## ğŸ“„ License
This project is licensed under the **MIT License**.

---

## ğŸ‘¤ Author
**Kadambala Eitish**  
ğŸ“§ eitishkadambala@gmail.com 
ğŸ”— [GitHub](https://github.com/Eitish24) | [LinkedIn](https://www.linkedin.com/in/kadambala-eitish0509/)





